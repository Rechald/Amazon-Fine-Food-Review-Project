{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purchase Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(readGz(\"train.json.gz\"))\n",
    "train_data = data[:100000]\n",
    "valid_data = data[100000:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epair =defaultdict(list)\n",
    "pair=[]\n",
    "businessID = set()\n",
    "userID = set()\n",
    "for l in data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  businessID.add(business)\n",
    "  userID.add(user)\n",
    "  epair[user].append(business)\n",
    "  pair.append((user,business))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "userID=list(userID)\n",
    "businessID=list(businessID)\n",
    "non_purchase_pairs=[]\n",
    "while count<100000:\n",
    "    random_user=random.choice(userID)\n",
    "    random_item=random.choice(businessID) \n",
    "    if random_item in epair[random_user]:\n",
    "        continue\n",
    "    else:\n",
    "        non_purchase_pairs.append((random_user,random_item))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_purchase_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for l in train_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  businessCount[business] += 1\n",
    "  totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPurchases/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=[]\n",
    "for l in valid_data:\n",
    "    valid.append((l['reviewerID'],l['itemID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=valid+non_purchase_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for i in validation:\n",
    "    if i[1] in return1:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[1]*100000\n",
    "list0=[0]*100000\n",
    "compare=list1+list0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get=[]\n",
    "for n in range(len(prediction)):\n",
    "    if prediction[n]==compare[n]:\n",
    "        get.append(1)\n",
    "    else:\n",
    "        get.append(0)\n",
    "acc=sum(get)/len(get)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy of the baseline model on the validation set I have built is 0.627585."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 \n",
    "original, popular = True, now \"totalPurchases/2\" as purchase prediction baseline, is it the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "acclist=[]\n",
    "for q in range(len(p)):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "      count += ic\n",
    "      return1.add(i)\n",
    "      if count > totalPurchases*p[q]: break\n",
    "    \n",
    "    return1=set(return1)\n",
    "    \n",
    "    pred=[]\n",
    "    for i in validation:\n",
    "        if i[1] in return1:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)  \n",
    "        \n",
    "    get=[]\n",
    "    for n in range(len(pred)):\n",
    "        if pred[n]==compare[n]:\n",
    "            get.append(1)\n",
    "        else:\n",
    "            get.append(0)\n",
    "    acc=sum(get)/len(get)\n",
    "    acclist.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54135,\n",
       " 0.574925,\n",
       " 0.601285,\n",
       " 0.620325,\n",
       " 0.63,\n",
       " 0.628415,\n",
       " 0.61549,\n",
       " 0.5918,\n",
       " 0.55586]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "acclist=[]\n",
    "for p in np.arange(0.4,0.6,0.01):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "      count += ic\n",
    "      return1.add(i)\n",
    "      if count > totalPurchases*p: break\n",
    "    \n",
    "    return1=set(return1)\n",
    "    \n",
    "    pred=[]\n",
    "    for i in validation:\n",
    "        if i[1] in return1:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)  \n",
    "        \n",
    "    get=[]\n",
    "    for n in range(len(pred)):\n",
    "        if pred[n]==compare[n]:\n",
    "            get.append(1)\n",
    "        else:\n",
    "            get.append(0)\n",
    "    acc=sum(get)/len(get)\n",
    "    acclist.append(acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acclist.index(max(acclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5300000000000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=np.arange(0.4,0.6,0.01)\n",
    "p[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As seen in the accuracy result, when we are using a threshold of the 53th percentile of popularity(choosing the top 53%), we are going to get a higher accuracy than the 50th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "build baseline when people purchase same category of item agian, return \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(iterables):  #function to spread items in lists in list\n",
    "    category=[]\n",
    "    for i in range(len(iterables)):\n",
    "        category+=iterables[i-1]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86ec5a34e05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_try\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewHash'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0muser_cate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0muser_cate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'categories'"
     ]
    }
   ],
   "source": [
    "user_cate=defaultdict(set)\n",
    "business_cate=defaultdict(set)\n",
    "categories=set()\n",
    "for l in data_try:\n",
    "    user,business,categories = l['reviewerID'],l['itemID'],l['categories']\n",
    "    categories=set(tuple(x) for x in categories)\n",
    "    user_cate[user]= user_cate[user]|categories\n",
    "    business_cate[business]= business_cate[business]|categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Clothing, Shoes & Jewelry', 'Anne Klein'),\n",
       " ('Clothing, Shoes & Jewelry', 'Available for International Shipping'),\n",
       " ('Clothing, Shoes & Jewelry', 'Fashion Watches'),\n",
       " ('Clothing, Shoes & Jewelry', 'Invicta'),\n",
       " ('Clothing, Shoes & Jewelry', 'Jewelry: International Shipping Available'),\n",
       " ('Clothing, Shoes & Jewelry', 'Men', 'Watches', 'Wrist Watches'),\n",
       " ('Clothing, Shoes & Jewelry', 'New Arrivals'),\n",
       " ('Clothing, Shoes & Jewelry', 'S', 'Steve Madden'),\n",
       " ('Clothing, Shoes & Jewelry',\n",
       "  'Shoes & Accessories: International Shipping Available'),\n",
       " ('Clothing, Shoes & Jewelry', 'Sport Watches'),\n",
       " ('Clothing, Shoes & Jewelry', 'Women', 'Shoes', 'Pumps'),\n",
       " ('Clothing, Shoes & Jewelry', 'Women', 'Watches', 'Wrist Watches')}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cate[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_final = []\n",
    "for l in validation:\n",
    "    user1,business1= l[0],l[1]\n",
    "    u = user_cate[user1]\n",
    "    b = business_cate[business1]\n",
    "    if set(u).intersection(set(b)):\n",
    "        predict_final.append(1)\n",
    "    else:\n",
    "        predict_final.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "get=[]\n",
    "for n in range(len(predict_final)):\n",
    "    if predict_final[n]==compare[n]:\n",
    "        get.append(1)\n",
    "    else:\n",
    "        get.append(0)\n",
    "acc=sum(get)/len(get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593255"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions1.csv\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    u1 = user_cate[u]\n",
    "    b1 = business_cate[i]\n",
    "    if set(u1).intersection(set(b1)):\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The accuracy is 0.592665."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 use \"pairsPurchase\" to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for l in train_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  businessCount[business] += 1\n",
    "  totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPurchases*0.53: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions.csv\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if i in return1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data1 = data[:100000]\n",
    "valid_data1 = data[100000:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "userv=[]\n",
    "itemv=[]\n",
    "for l in valid_data1:\n",
    "    userv.append(l['reviewerID'])\n",
    "    itemv.append(l['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairv = [(x, y) for x, y in zip(userv,itemv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "for l in train_data1:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  allRatings.append(l['rating'])\n",
    "  userRatings[user].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "mse=0\n",
    "for l in valid_data1:\n",
    "    mse += (l['rating']-globalAverage)**2\n",
    "MSE=mse/len(pairv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.0, 5.0, 3.0, 5.0, 5.0, 3.0, 4.0, 2.0, 4.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingv=[]\n",
    "for l in valid_data1:\n",
    "    ratingv.append(l['rating'])\n",
    "ratingv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.232"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.222481119999121"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy(MSE) of the trivial predictor on the validation set is 1.222481119999121. Alpha equals to globalAverage which is 4.23151."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 rating(user; item) ' apha + beta user + beta item; lamda=1 report MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get initial alpha betau betai\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "itemRatings = defaultdict(list)\n",
    "for l in train_data1:\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "    itemRatings[item].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "itemAverage = {}\n",
    "for i in itemRatings:\n",
    "    itemAverage[i] = sum(itemRatings[i]) / len(itemRatings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define function for joint convex\n",
    "def difference(averagedic, averagedic_last, compare):\n",
    "    margin = 0\n",
    "    for i in averagedic:\n",
    "        margin += abs(averagedic[i] - averagedic_last[i])\n",
    "    if margin < compare:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update alpha betau betai\n",
    "def convex(globalAverage, userAverage, itemAverage,lam,compare):\n",
    "    end = False\n",
    "    globalAverage_last = globalAverage\n",
    "    userAverage_last = userAverage\n",
    "    itemAverage_last = itemAverage\n",
    "    while not end:\n",
    "        # update globalAverage\n",
    "        n = len(train_data)\n",
    "        globalAverage = 0\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            globalAverage += (l[\"rating\"] - (userAverage_last[user]+ itemAverage_last[item]))\n",
    "        globalAverage = globalAverage/n\n",
    "        \n",
    "        # update userAverage\n",
    "        nitems = defaultdict(int)\n",
    "        for user in userAverage:\n",
    "            userAverage[user] = 0\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            nitems[user] += 1\n",
    "            userAverage[user] += (l[\"rating\"] - (globalAverage+itemAverage_last[item]))\n",
    "        for user in userAverage:\n",
    "            userAverage[user] = userAverage[user]/(lam + abs(nitems[user]))\n",
    "        \n",
    "        # update businessAverage\n",
    "        nuser = defaultdict(int)\n",
    "        for item in itemAverage:\n",
    "            itemAverage[item] = 0\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            nuser[item] += 1\n",
    "            itemAverage[item] += (l[\"rating\"] - (globalAverage + userAverage[user]))\n",
    "        for item in itemAverage:\n",
    "            itemAverage[item] = itemAverage[item]/(lam + abs(nuser[item]))\n",
    "        \n",
    "        #print ((globalAverage - globalAverage_last)**2)\n",
    "        #compare=0.01\n",
    "        if abs(globalAverage - globalAverage_last)<compare and difference(userAverage, userAverage_last, compare) and difference(itemAverage, itemAverage_last, compare):\n",
    "            end = True\n",
    "        else:\n",
    "            globalAverage_last = globalAverage\n",
    "            userAverage_last = userAverage\n",
    "            itemAverage_last = itemAverage\n",
    "    return globalAverage, userAverage, itemAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_globalAverage,final_userAverage, final_itemAverage=convex(globalAverage,userAverage, itemAverage,1,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.225832905994302"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "##report mse on validation set\n",
    "def cal_mse(final_globalAverage, final_userAverage, final_itemAverage):\n",
    "    mse = 0.0\n",
    "    userlist = []\n",
    "    itemlist = []\n",
    "    for i in final_userAverage:\n",
    "        userlist.append(i)\n",
    "    for j in final_itemAverage:\n",
    "        itemlist.append(j)\n",
    "    for l in valid_data:\n",
    "        user,item = l['reviewerID'],l['itemID']\n",
    "        if (user in userlist) and (item in itemlist):\n",
    "            mse += (l[\"rating\"]-final_globalAverage-final_userAverage[user]-final_itemAverage[item])**2\n",
    "        elif (user in userlist) and (item not in itemlist):\n",
    "            mse += (l[\"rating\"]-final_globalAverage-final_userAverage[user])**2\n",
    "        elif (user not in userlist) and (item in itemlist):\n",
    "            mse += (l[\"rating\"]-final_globalAverage-final_itemAverage[item])**2\n",
    "        else:\n",
    "            mse += (l[\"rating\"]-final_globalAverage)**2\n",
    "    mse /= 100000\n",
    "    print(\"mean square error on validation data is \" +str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error on validation data is 1.2811186591058816\n"
     ]
    }
   ],
   "source": [
    "cal_mse(final_globalAverage, final_userAverage, final_itemAverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7 report use&item ID with largest/ lowest value of beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID that have the largest values of beta is  U495776285 ,the beta value is  1.4867483773308852\n"
     ]
    }
   ],
   "source": [
    "inverse_user = [(value, key) for key, value in final_userAverage.items()]\n",
    "print('The user ID that have the largest values of beta is ',max(inverse_user)[1],',the beta value is ',max(inverse_user)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID that have the smallest values of beta is  U204516481 ,the beta value is  -2.5517077142613376\n"
     ]
    }
   ],
   "source": [
    "inverse_user = [(value, key) for key, value in final_userAverage.items()]\n",
    "print('The user ID that have the smallest values of beta is ',min(inverse_user)[1],',the beta value is ',min(inverse_user)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item ID that have the largest values of beta is  I809804570 ,the beta value is  1.2700486631942407\n"
     ]
    }
   ],
   "source": [
    "inverse_item = [(value, key) for key, value in final_itemAverage.items()]\n",
    "print('The item ID that have the largest values of beta is ',max(inverse_item)[1],',the beta value is ',max(inverse_item)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item ID that have the smallest values of beta is  I511389419 ,the beta value is  -2.5756646326290698\n"
     ]
    }
   ],
   "source": [
    "inverse_item = [(value, key) for key, value in final_itemAverage.items()]\n",
    "print('The item ID that have the smallest values of beta is ',min(inverse_item)[1],',the beta value is ',min(inverse_item)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8 find a better lamda for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error on validation data is 1.8621883545995428\n",
      "mean square error on validation data is 1.8988131471912073\n",
      "mean square error on validation data is 1.7488630442796071\n",
      "mean square error on validation data is 1.2811186589872874\n",
      "mean square error on validation data is 1.1998248180264501\n"
     ]
    }
   ],
   "source": [
    "lam=[0,0.01,0.1,1,100]\n",
    "for m in lam:  \n",
    "    final_globalAverage,final_userAverage, final_itemAverage=convex(globalAverage,userAverage, itemAverage,m,0.00001)\n",
    "    cal_mse(final_globalAverage, final_userAverage, final_itemAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error on validation data is 1.1398956062804486\n",
      "mean square error on validation data is 1.1379239648287354\n",
      "mean square error on validation data is 1.1376840308598197\n",
      "mean square error on validation data is 1.1377680417270668\n"
     ]
    }
   ],
   "source": [
    "lam=[5,6,6.5,7]\n",
    "for m in lam:  \n",
    "    final_globalAverage,final_userAverage, final_itemAverage=convex(globalAverage,userAverage, itemAverage,m,0.00001)\n",
    "    cal_mse(final_globalAverage, final_userAverage, final_itemAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error on validation data is 1.1377354027244155\n",
      "mean square error on validation data is 1.1377040237193359\n"
     ]
    }
   ],
   "source": [
    "lam=[6.3,6.4]\n",
    "for m in lam:  \n",
    "    final_globalAverage,final_userAverage, final_itemAverage=convex(globalAverage,userAverage, itemAverage,m,0.00001)\n",
    "    cal_mse(final_globalAverage, final_userAverage, final_itemAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error on validation data is 1.1376780224542182\n"
     ]
    }
   ],
   "source": [
    "lam=[6.6]\n",
    "for m in lam:  \n",
    "    final_globalAverage,final_userAverage, final_itemAverage=convex(globalAverage,userAverage, itemAverage,m,0.00001)\n",
    "    cal_mse(final_globalAverage, final_userAverage, final_itemAverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best lamda I can find is 6.6 and the MSE of this model is 1.1376780201574763."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the test set to generate prediction \n",
    "## get initial alpha betau betai\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "itemRatings = defaultdict(list)\n",
    "for l in train_data:\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "    itemRatings[item].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "itemAverage = {}\n",
    "for i in itemRatings:\n",
    "    itemAverage[i] = sum(itemRatings[i]) / len(itemRatings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_globalAverage,test_userAverage, test_itemAverage=convex(globalAverage,userAverage, itemAverage,6.6,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "##report mse on test set\n",
    "mse = 0.0\n",
    "userlist = []\n",
    "itemlist = []\n",
    "for i in test_userAverage:\n",
    "    userlist.append(i)\n",
    "for j in test_itemAverage:\n",
    "    itemlist.append(j)\n",
    "predictions = open(\"predictionsq8.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')    \n",
    "    if (u in userlist) and (i in itemlist):\n",
    "        rating=test_globalAverage+test_userAverage[u]+test_itemAverage[i]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    elif (u in userlist) and (i not in itemlist):\n",
    "        rating=test_globalAverage+test_userAverage[u]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    elif (u not in userlist) and (i in itemlist):\n",
    "        rating=test_globalAverage+test_itemAverage[i]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    else:\n",
    "        rating=test_globalAverage\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "predictions.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
